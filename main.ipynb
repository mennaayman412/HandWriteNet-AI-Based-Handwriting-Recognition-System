{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c119a5ad-0713-4391-a32d-cf1420803288",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfa10e6-3931-4009-ac42-09d79a4b18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "data_inp=np.loadtxt('csvTrainImages 60k x 784.csv',delimiter=',')\n",
    "data_out=np.loadtxt('csvTrainLabel 60k x 1.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4502cd6d-3f44-444e-83bf-20182c4eb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "pixels = data_inp[8].tolist()\n",
    "\n",
    "\n",
    "# 2. تأكدي إن عدد القيم 784 (يعني صورة 28x28)\n",
    "assert len(pixels) == 784, \"لازم عدد القيم يكون 784\"\n",
    "\n",
    "# 3. نحول القائمة لمصفوفة 2D\n",
    "img_array = np.array(pixels, dtype=np.uint8).reshape((28, 28))\n",
    "\n",
    "# 4. نحولها لصورة رمادية\n",
    "img = Image.fromarray(img_array, mode='L')  # 'L' = grayscale\n",
    "\n",
    "# 5. لو عايزة تكبري الصورة عشان تبقي أوضح\n",
    "img = img.resize((280, 280), resample=Image.NEAREST)\n",
    "\n",
    "# 6. اعرضي أو احفظي الصورة\n",
    "img.show()            # لعرض الصورة\n",
    "# img.save(\"output.png\")  # لحفظ الصورة في ملف\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88e5ad5-5461-40f3-b6df-e4a6e7b8f7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input is: (60000, 784)\n",
      "The shape of output is: (60000,)\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of input is: ' + str(data_inp.shape))\n",
    "print ('The shape of output is: ' + str(data_out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e434135d-2b3a-4a15-9531-511b1cd42796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential(\n",
    "    [tf.keras.Input(shape=(784,)),\n",
    "    Dense(25,activation='relu',name=\"L1\"),\n",
    "    Dense(15,activation='relu',name=\"L2\"),\n",
    "    Dense(10,activation='linear',name=\"L3\"),\n",
    "    ], name = \"my_model\"                                           \n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4095419-5bc0-458a-aa8a-3903661f7787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ L1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,625</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ L2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ L3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ L1 (\u001b[38;5;33mDense\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │          \u001b[38;5;34m19,625\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ L2 (\u001b[38;5;33mDense\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ L3 (\u001b[38;5;33mDense\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m160\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,175</span> (78.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,175\u001b[0m (78.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,175</span> (78.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,175\u001b[0m (78.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b45964f-78e8-4422-b521-2a5250c711cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    ,metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d015fa29-8da7-433f-9835-2a9cc151100f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4429 - loss: 4.0103\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6712 - loss: 0.8554\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8149 - loss: 0.5373\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9395 - loss: 0.2452\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9617 - loss: 0.1589\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9684 - loss: 0.1298\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9715 - loss: 0.1109\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9745 - loss: 0.0997\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9783 - loss: 0.0865\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9816 - loss: 0.0758\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9809 - loss: 0.0747\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9839 - loss: 0.0627\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9845 - loss: 0.0597\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9844 - loss: 0.0602\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9868 - loss: 0.0509\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9866 - loss: 0.0532\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9868 - loss: 0.0495\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9877 - loss: 0.0496\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9869 - loss: 0.0512\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9884 - loss: 0.0456\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    data_inp,data_out,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b69ecf4d-c2fc-4f04-83ac-dabb5f036fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9874 - loss: 0.0492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.046545688062906265, 0.9876166582107544]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data_inp,data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaff282d-83b8-4a66-90f2-e692c9d6bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"When applying the model to the provided dataset, \n",
    "it was observed that the model's performance was relatively low in terms of accuracy compared to \n",
    "what is typically expected in classification tasks such as MNIST.\"\n",
    "\"\"\"\n",
    "\n",
    "test_out=np.loadtxt('csvTestLabel 10k x 1.csv',delimiter=',')\n",
    "test_inp=np.loadtxt('csvTestImages 10k x 784.csv',delimiter=',')\n",
    "y_test=model.predict(test_inp)\n",
    "y_pred_labels = np.argmax(y_test, axis=1) \n",
    "y_pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15d88819-1739-46d5-bd6d-af0cc55f21d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Balanced Accuracy: 0.97\n",
      "Precision: 0.97\n",
      "Recall: 0.97\n",
      "F1-Score: 0.97\n",
      "Matthews Correlation Coefficient (MCC): 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_classes = y_pred_labels\n",
    "y_true=test_out\n",
    "\n",
    "# حساب المقاييس\n",
    "accuracy = accuracy_score(y_true,y_pred_classes )\n",
    "balanced_accuracy = balanced_accuracy_score(y_true, y_pred_classes)\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')  # \"weighted\" لأخذ الفئات غير المتوازنة بالاعتبار\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "mcc = matthews_corrcoef(y_true, y_pred_classes)\n",
    "#total_params = model.count_params()\n",
    "\n",
    "# طباعة النتائج\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.2f}\")\n",
    "\n",
    "#print(f\"Model Complexity (Parameters): {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "496914cf-f8e0-434b-8eaf-69bb16ddd1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1\n",
      "real 1\n"
     ]
    }
   ],
   "source": [
    "n=41\n",
    "p_ind=list(p[n]).index(max(list(p[n])))\n",
    "print(\"model\",p_ind)\n",
    "print(\"real\",int(test_out[n]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9977417-fdce-4885-b0fa-019f0aa3624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_in_arabic = [\"صفر\", \"واحد\", \"اثنان\", \"ثلاثة\", \"أربعة\", \"خمسة\", \"ستة\", \"سبعة\", \"ثمانية\", \"تسعة\"]\n",
    "def convrt():\n",
    "    # Load the image using OpenCV\n",
    "    image_path = \"resized_image.png\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n",
    "    \n",
    "    # Convert the image to a 2D array of pixels\n",
    "    pixel_array = np.array(255-image).T\n",
    "    \n",
    "    # If you need a flat array, use .flatten()\n",
    "    flat_pixel_array = pixel_array.flatten()\n",
    "    test_sample = np.expand_dims(flat_pixel_array, axis=0)  \n",
    "    t= model.predict(test_sample).flatten().tolist()\n",
    "    output=t.index(max(t))\n",
    "    status_label.config(text=numbers_in_arabic[output])  \n",
    "\n",
    "               \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5825c1f6-71cd-44a5-a013-49ff3ca4a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Function to save the canvas content as a 28x28 image\n",
    "def save_canvas():\n",
    "    canvas_image = Image.new(\"RGB\", (280, 280), \"white\")\n",
    "    canvas_image.paste(image, (0, 0))\n",
    "    resized_image = canvas_image.resize((28, 28), Image.Resampling.LANCZOS).convert(\"L\")  # Grayscale\n",
    "    resized_image.save(\"resized_image.png\")\n",
    "    convrt()\n",
    "\n",
    "# Function to draw on the canvas\n",
    "def paint(event):\n",
    "    brush_size = 10  # Set brush size (thickness)\n",
    "    x1, y1 = (event.x - brush_size), (event.y - brush_size)\n",
    "    x2, y2 = (event.x + brush_size), (event.y + brush_size)\n",
    "    canvas.create_oval(x1, y1, x2, y2, fill=\"black\", outline=\"black\")\n",
    "    draw.ellipse([x1, y1, x2, y2], fill=\"black\")  # Update Pillow image with thicker brush\n",
    "\n",
    "# Function to clear the canvas\n",
    "def clear_canvas():\n",
    "    canvas.delete(\"all\")\n",
    "    draw.rectangle((0, 0, 280, 280), fill=\"white\")\n",
    "\n",
    "# Create the main tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"AI Handwriting Recognizer\")\n",
    "\n",
    "# Create a canvas for drawing\n",
    "canvas = tk.Canvas(root, width=280, height=280, bg=\"white\")\n",
    "canvas.pack()\n",
    "\n",
    "# Create a PIL image for saving the drawing\n",
    "image = Image.new(\"RGB\", (280, 280), \"white\")  # Match canvas size\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Bind mouse events to the canvas\n",
    "canvas.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "# Add buttons for saving and clearing the canvas\n",
    "save_button = tk.Button(root, text=\"done\", command=save_canvas)\n",
    "save_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "clear_button = tk.Button(root, text=\"Clear\", command=clear_canvas)\n",
    "clear_button.pack(side=\"right\", padx=10)\n",
    "status_label=tk.Label(root, text=\"\", bg=\"green\", fg=\"white\" ,font=\"50px\",height=2)\n",
    "status_label.pack(fill=\"x\", pady=5)\n",
    "# Run the tkinter main loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61a42c5e-1c73-4e0a-98a0-fb834becf712",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flat_pixel_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(\u001b[43mflat_pixel_array\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[0;32m      2\u001b[0m t\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_sample)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mmax\u001b[39m(t\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'flat_pixel_array' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bcacd-9318-44ec-bbf5-9da9cb030e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e5ad5-6f56-426a-8c76-90569603cacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
